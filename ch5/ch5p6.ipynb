{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51a55c7b",
   "metadata": {},
   "source": [
    "# 5.6 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0640c795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cpu'), device(type='cuda'), device(type='cuda', index=1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "torch.device('cpu'), torch.device('cuda'), torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f51715ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d5d8d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cpu'), device(type='cpu'), [device(type='cpu')])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def try_gpu(i=0):  #@save\n",
    "    \"\"\"如果存在，则返回gpu(i)，否则返回cpu()\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "def try_all_gpus():  #@save\n",
    "    \"\"\"返回所有可用的GPU，如果没有GPU，则返回[cpu(),]\"\"\"\n",
    "    devices = [torch.device(f'cuda:{i}')\n",
    "             for i in range(torch.cuda.device_count())]\n",
    "    return devices if devices else [torch.device('cpu')]\n",
    "\n",
    "try_gpu(), try_gpu(10), try_all_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a111590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0829a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones(2, 3, device=try_gpu())\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de079962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5249, 0.7750, 0.8525],\n",
       "        [0.5575, 0.5507, 0.2106]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = torch.rand(2, 3, device=try_gpu(1))\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759122d4",
   "metadata": {},
   "source": [
    "## M1 Config for d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb36984",
   "metadata": {},
   "source": [
    "Blog 里指定的 d2l==0.17.6 M 芯片不兼容，去掉版本号。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc403c4",
   "metadata": {},
   "source": [
    "## Pytorch for Apple Silicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b549010c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__\n",
    "torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a52f557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7821, 0.1719, 0.9009, 0.3457, 0.0928],\n",
      "        [0.4093, 0.7747, 0.3700, 0.7459, 0.4032],\n",
      "        [0.7861, 0.9759, 0.1333, 0.1236, 0.3908]])\n",
      "mps\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(3,5)\n",
    "print(a)\n",
    "b = torch.device('mps')\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "928f616b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Time: 0.336871862411499\n",
      "GPU Time: 0.15578484535217285\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# 创建随机矩阵\n",
    "a = torch.randn(10000, 1000)\n",
    "b = torch.randn(1000, 10000)\n",
    "\n",
    "# CPU计算\n",
    "t0 = time.time()\n",
    "c = torch.matmul(a, b)\n",
    "t1 = time.time()\n",
    "print(\"CPU Time:\", t1 - t0)\n",
    "\n",
    "# 将数据移动到GPU\n",
    "device = torch.device('mps')\n",
    "a = a.to(device)\n",
    "b = b.to(device)\n",
    "\n",
    "# GPU计算\n",
    "t2 = time.time()\n",
    "c = torch.matmul(a, b)\n",
    "t3 = time.time()\n",
    "print(\"GPU Time:\", t3 - t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8128c469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/d2l/lib/python3.9/site-packages/torch/_tensor_str.py:103: UserWarning: The operator 'aten::bitwise_and.Tensor_out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  nonzero_finite_vals = torch.masked_select(tensor_view, torch.isfinite(tensor_view) & tensor_view.ne(0))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]], device='mps:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones(2, 3, device=torch.device('mps'))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb08be4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(3, 1))\n",
    "net = net.to(device=torch.device('mps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1b4635e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2598],\n",
       "        [0.2598]], device='mps:0', grad_fn=<MpsLinearBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d51c096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data.device"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
