{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae4be1bb",
   "metadata": {},
   "source": [
    "# 3.4 softmax 回归"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f748f9e2",
   "metadata": {},
   "source": [
    "## 练习题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d71b1a3",
   "metadata": {},
   "source": [
    "练习题 1：我们可以更深入地探讨指数族与softmax之间的联系\n",
    "\n",
    "* 计算 softmax 交叉熵损失 $l(\\mathbf{y},\\hat{\\mathbf{y}})$ 的二阶导数。\n",
    "\n",
    "* 计算 softmax(o) 给出的分布方差，并与上面计算的二阶导数匹配"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dbfef9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e8195b5",
   "metadata": {},
   "source": [
    "练习题 2：假设我们有三个类发生的概率相等，即概率向量是 $(\\frac{1}{3}, \\frac{1}{3}, \\frac{1}{3})$\n",
    "\n",
    "* 如果我们尝试为它设计二进制代码，有什么问题\n",
    "* 请设计一个更好的代码。提示：如果我们尝试编码两个独立的观察结果会发生什么？如果我们联合编码 n 个观测值怎么办"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07815b03",
   "metadata": {},
   "source": [
    "\n",
    "采用 one-hot 独热编码，分别设置为 001、010、100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d70193",
   "metadata": {},
   "source": [
    "练习题 3：softmax 是对上面介绍的映射的误称（虽然深度学习领域中很多人都使用这个名字）。真正的 softmax 被定义为\n",
    "$$\n",
    "\\mathrm{RealSoftMax}(a, b) = \\log (\\exp(a) + \\exp(b))\n",
    "$$\n",
    "\n",
    "* 证明 $\\mathrm{RealSoftMax}(a, b) > \\mathrm{max}(a, b)$\n",
    "* 证明 $\\lambda^{-1} \\mathrm{RealSoftMax}(\\lambda a, \\lambda b) > \\mathrm{max}(a, b)$ 成立，前提是 $\\lambda > 0$\n",
    "* 证明对于 $\\lambda \\to \\infty$，有 $\\lambda^{-1} \\mathrm{RealSoftMax}(\\lambda a, \\lambda b) \\to \\mathrm{max}(a, b)$\n",
    "* soft-min 会是什么样子？\n",
    "* 将其扩展到两个以上的数字"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5be140",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
