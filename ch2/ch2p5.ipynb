{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7483700",
   "metadata": {},
   "source": [
    "# 2.5 自动微分"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa35bc7",
   "metadata": {},
   "source": [
    "## 实验代码运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a054030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mxnet import autograd, np, npx\n",
    "\n",
    "npx.set_np()\n",
    "\n",
    "x = np.arange(4.0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84e40d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过调用attach_grad来为一个张量的梯度分配内存\n",
    "x.attach_grad()\n",
    "# 在计算关于x的梯度后，将能够通过'grad'属性访问它，它的值被初始化为0\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce4a45a",
   "metadata": {},
   "source": [
    "对函数 $y = 2 \\bm{x}^T\\bm{x}$ ，对列向量 $\\bm{x}$ 求导。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eb27794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(28.)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把代码放到autograd.record内，以建立计算图\n",
    "with autograd.record():\n",
    "    y = 2 * np.dot(x, x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18fc08b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  4.,  8., 12.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2257481a",
   "metadata": {},
   "source": [
    "函数 $y = 2 \\bm{x}^T \\bm{x}$ 关于 $\\bm{x}$ 的梯度应为 $4\\bm{x}$，验证是否正确："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cd4cbc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad == 4 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "306e6d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with autograd.record():\n",
    "    y = x.sum()\n",
    "y.backward()\n",
    "x.grad  # 被新计算的梯度覆盖"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0256b091",
   "metadata": {},
   "source": [
    "非标量变量的方向传播："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41666621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 当对向量值变量y（关于x的函数）调用backward时，将通过对y中的元素求和来创建\n",
    "# 一个新的标量变量。然后计算这个标量变量相对于x的梯度\n",
    "with autograd.record():\n",
    "    y = x * x  # y是一个向量\n",
    "y.backward()\n",
    "x.grad  # 等价于y=sum(x*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "190daafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with autograd.record():\n",
    "    y = x * x\n",
    "    u = y.detach()\n",
    "    z = u * x\n",
    "z.backward()\n",
    "x.grad == u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45326069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad == 2 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8249850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(a):\n",
    "    b = a * 2\n",
    "    while np.linalg.norm(b) < 1000:\n",
    "        b = b * 2\n",
    "    if b.sum() > 0:\n",
    "        c = b\n",
    "    else:\n",
    "        c = 100 * b\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ca152f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.normal()\n",
    "a.attach_grad()\n",
    "with autograd.record():\n",
    "    d = f(a)\n",
    "d.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "697e546c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad == d / a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d499f9ab",
   "metadata": {},
   "source": [
    "## 练习题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de29347b",
   "metadata": {},
   "source": [
    "练习题 1：为什么计算二阶导数比计算一阶导数的开销要更大？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ee2682",
   "metadata": {},
   "source": [
    "因为计算二阶导数需要计算一阶导数，开销就会更大。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b391ba",
   "metadata": {},
   "source": [
    "练习题 2：在运行反向传播函数之后，立即再次运行它，看看会发生什么\n",
    "\n",
    "Cannot differentiate node because it is not in a computational graph. \n",
    "\n",
    "前向过程建立的计算图，会在反向传播后释放，所以第二次运行反向传播就会出错。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a848587e",
   "metadata": {},
   "outputs": [
    {
     "ename": "MXNetError",
     "evalue": "Traceback (most recent call last):\n  File \"../src/imperative/imperative.cc\", line 295\nMXNetError: Check failed: !AGInfo: :IsNone(*i): Cannot differentiate node because it is not in a computational graph. You need to set is_recording to true or use autograd.record() to save computational graphs for backward. If you want to differentiate the same graph twice, you need to pass retain_graph=True to backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m y\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m      4\u001b[0m x\u001b[38;5;241m.\u001b[39mgrad  \u001b[38;5;66;03m# 等价于y=sum(x*x)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/d2l/lib/python3.9/site-packages/mxnet/ndarray/ndarray.py:2864\u001b[0m, in \u001b[0;36mNDArray.backward\u001b[0;34m(self, out_grad, retain_graph, train_mode)\u001b[0m\n\u001b[1;32m   2861\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2862\u001b[0m     ograd_handles \u001b[38;5;241m=\u001b[39m [out_grad\u001b[38;5;241m.\u001b[39mhandle]\n\u001b[0;32m-> 2864\u001b[0m \u001b[43mcheck_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMXAutogradBackwardEx\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2865\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_handle_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mc_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNDArrayHandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mograd_handles\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2867\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2868\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_void_p\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2869\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_mode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_void_p\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_void_p\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/d2l/lib/python3.9/site-packages/mxnet/base.py:246\u001b[0m, in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03mThis function will raise an exception when an error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;124;03m    return value from API calls.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m get_last_ffi_error()\n",
      "\u001b[0;31mMXNetError\u001b[0m: Traceback (most recent call last):\n  File \"../src/imperative/imperative.cc\", line 295\nMXNetError: Check failed: !AGInfo: :IsNone(*i): Cannot differentiate node because it is not in a computational graph. You need to set is_recording to true or use autograd.record() to save computational graphs for backward. If you want to differentiate the same graph twice, you need to pass retain_graph=True to backward."
     ]
    }
   ],
   "source": [
    "with autograd.record():\n",
    "    y = x * x  # y是一个向量\n",
    "y.backward()\n",
    "x.grad  # 等价于y=sum(x*x)\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860ba6d8",
   "metadata": {},
   "source": [
    "练习题 3：在控制流的例子中，我们计算d关于a的导数，如果将变量a更改为随机向量或矩阵，会发生什么？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79da4d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'mxnet.numpy' has no attribute 'randn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m(size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'mxnet.numpy' has no attribute 'randn'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81261023",
   "metadata": {},
   "source": [
    "练习题 4：重新设计一个求控制流梯度的例子，运行并分析结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2dddea9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(a):\n",
    "    if a.sum() > 0:\n",
    "        c = a\n",
    "    else:\n",
    "        c = 10 * a\n",
    "    return c\n",
    "\n",
    "a = np.random.normal()\n",
    "a.attach_grad()\n",
    "with autograd.record():\n",
    "    d = f(a)\n",
    "d.backward()\n",
    "\n",
    "a.grad == d / a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056d98e2",
   "metadata": {},
   "source": [
    "练习题 5：使 $f(x) = sin(x)$，绘制 $f(x)$ 和 $\\frac{df(x)}{dx}$ 的图像，其中后者不使用 $f^\\prime (x) = cos(x)$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
